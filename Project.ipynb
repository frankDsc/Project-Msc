{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e53b2a-bb33-4be3-b939-71a1fb23287f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DPT+RANSAC\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import DPTForDepthEstimation, DPTFeatureExtractor\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import RANSACRegressor\n",
    "\n",
    "# DPT\n",
    "model_name = \"Intel/dpt-large\"\n",
    "dpt_model = DPTForDepthEstimation.from_pretrained(model_name)\n",
    "feature_extractor = DPTFeatureExtractor.from_pretrained(model_name)\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "dpt_model.to(device)\n",
    "\n",
    "def load_and_process_data(csv_path, images_folder_paths):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    samples = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        image_name = row['image_name']\n",
    "        image_path = find_image(images_folder_paths, image_name)\n",
    "        if not image_path:\n",
    "            continue\n",
    "        \n",
    "        image = Image.open(image_path)\n",
    "        x_coord, y_coord = int(row['x']), int(row['y'])\n",
    "        if not (0 <= x_coord < image.width and 0 <= y_coord < image.height):\n",
    "            continue\n",
    "        \n",
    "        true_depth = row['radius']\n",
    "        inputs = feature_extractor(images=image, return_tensors=\"pt\").to(device)\n",
    "        with torch.no_grad():\n",
    "            outputs = dpt_model(**inputs)\n",
    "            predicted_depth = outputs.predicted_depth.squeeze()\n",
    "        \n",
    "        predicted_depth_array = torch.nn.functional.interpolate(\n",
    "            predicted_depth.unsqueeze(0).unsqueeze(0),\n",
    "            size=image.size[::-1],\n",
    "            mode=\"bicubic\",\n",
    "            align_corners=False,\n",
    "        ).squeeze().cpu().numpy()\n",
    "        \n",
    "        predicted_depth = predicted_depth_array[y_coord, x_coord]\n",
    "        samples.append((predicted_depth, true_depth, row['location']))\n",
    "\n",
    "    return samples\n",
    "\n",
    "def find_image(folder_paths, image_name):\n",
    "    for folder_path in folder_paths:\n",
    "        for root, _, files in os.walk(folder_path):\n",
    "            if image_name in files:\n",
    "                return os.path.join(root, image_name)\n",
    "    return None\n",
    "\n",
    "def train_ransac(samples):\n",
    "    X = np.array([s[0] for s in samples]).reshape(-1, 1)\n",
    "    y = np.array([s[1] for s in samples])\n",
    "    \n",
    "    ransac = RANSACRegressor(max_trials=200, min_samples=0.5, residual_threshold=2.0, random_state=42)\n",
    "    ransac.fit(X, y)\n",
    "    \n",
    "    inlier_mask = ransac.inlier_mask_\n",
    "    outlier_mask = np.logical_not(inlier_mask)\n",
    "    \n",
    "    return ransac, inlier_mask, outlier_mask\n",
    "\n",
    "def evaluate_samples(samples, model):\n",
    "    X = np.array([s[0] for s in samples]).reshape(-1, 1)\n",
    "    y_true = np.array([s[1] for s in samples])\n",
    "    y_pred = model.predict(X)\n",
    "    \n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    \n",
    "    return mae, mse, y_true, y_pred\n",
    "\n",
    "def plot_results(train_samples, val_samples, test_samples, model, inlier_mask):\n",
    "    def plot_fit_line(ax, X, y, y_pred, title, x_label, y_label):\n",
    "        ax.scatter(y, y_pred, alpha=0.5, label='Predicted vs True')\n",
    "        ax.set_xlabel(x_label)\n",
    "        ax.set_ylabel(y_label)\n",
    "        ax.set_title(title)\n",
    "        ax.legend()\n",
    "        ax.grid(True)\n",
    "        min_val = min(y.min(), y_pred.min())\n",
    "        max_val = max(y.max(), y_pred.max())\n",
    "        ax.plot([min_val, max_val], [min_val, max_val], color='red', linewidth=2, label='x=y')\n",
    "        fit_line = np.poly1d(np.polyfit(y, y_pred, 1))\n",
    "        fit_y = fit_line(y)\n",
    "        ax.plot(y, fit_y, color='blue', linewidth=2, label='Fit Line')\n",
    "        ax.legend()\n",
    "\n",
    "        \n",
    "        fit_slope = fit_line.c[0]\n",
    "        angle = np.arctan(fit_slope) - np.pi / 4\n",
    "        angle_deg = np.degrees(angle)\n",
    "        print(f\"Angle between x=y and fit line in {title}: {angle_deg:.2f} degrees\")\n",
    "\n",
    "    plt.figure(figsize=(18, 5))\n",
    "    \n",
    "    X_train = np.array([s[0] for s in train_samples]).reshape(-1, 1)\n",
    "    y_train = np.array([s[1] for s in train_samples])\n",
    "    X_val = np.array([s[0] for s in val_samples]).reshape(-1, 1)\n",
    "    y_val = np.array([s[1] for s in val_samples])\n",
    "    X_test = np.array([s[0] for s in test_samples]).reshape(-1, 1)\n",
    "    y_test = np.array([s[1] for s in test_samples])\n",
    "    \n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_val_pred = model.predict(X_val)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    \n",
    "    plt.subplot(1, 3, 1)\n",
    "    plot_fit_line(plt.gca(), X_train, y_train, y_train_pred, 'Training Set', 'True Depth', 'Predicted Depth')\n",
    "    \n",
    "    plt.subplot(1, 3, 2)\n",
    "    plot_fit_line(plt.gca(), X_val, y_val, y_val_pred, 'Validation Set', 'True Depth', 'Predicted Depth')\n",
    "    \n",
    "    plt.subplot(1, 3, 3)\n",
    "    plot_fit_line(plt.gca(), X_test, y_test, y_test_pred, 'Test Set', 'True Depth', 'Predicted Depth')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # 绘制训练集的拟合线\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.scatter(y_train, y_train_pred, alpha=0.5, label='Train Set')\n",
    "    plt.xlabel('True Depth')\n",
    "    plt.ylabel('Predicted Depth')\n",
    "    plt.title('Training Set Fit Line')\n",
    "    plt.plot([min(y_train), max(y_train)], [min(y_train), max(y_train)], color='red', linewidth=2, label='x=y')\n",
    "    fit_line = np.poly1d(np.polyfit(y_train, y_train_pred, 1))\n",
    "    fit_y = fit_line(y_train)\n",
    "    plt.plot(y_train, fit_y, color='blue', linewidth=2, label='Fit Line')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "    fit_slope = fit_line.c[0]\n",
    "    angle = np.arctan(fit_slope) - np.pi / 4\n",
    "    angle_deg = np.degrees(angle)\n",
    "    print(f\"Angle between x=y and fit line in Training Set: {angle_deg:.2f} degrees\")\n",
    "\n",
    "    print(f\"RANSAC model coefficients: {model.estimator_.coef_}\")\n",
    "    print(f\"RANSAC model intercept: {model.estimator_.intercept_}\")\n",
    "\n",
    "\n",
    "csv_path = r\"C:\\Users\\D-Frank\\Desktop\\111.csv\"\n",
    "images_folder_paths = [\n",
    "    r\"C:\\Users\\D-Frank\\Desktop\\data\\104RECNX\",\n",
    "    r\"C:\\Users\\D-Frank\\Desktop\\data\\105RECNX\",\n",
    "    r\"C:\\Users\\D-Frank\\Desktop\\data\\106RECNX\",\n",
    "    r\"C:\\Users\\D-Frank\\Desktop\\data\\107RECNX\",\n",
    "    r\"C:\\Users\\D-Frank\\Desktop\\data\\108RECNX\",\n",
    "    r\"C:\\Users\\D-Frank\\Desktop\\data\\110RECNX\",\n",
    "    r\"C:\\Users\\D-Frank\\Desktop\\data\\100RECNX\",\n",
    "    r\"C:\\Users\\D-Frank\\Desktop\\data\\101RECNX\",\n",
    "    r\"C:\\Users\\D-Frank\\Desktop\\data\\102RECNX\",\n",
    "    r\"C:\\Users\\D-Frank\\Desktop\\data\\103RECNX\"\n",
    "]\n",
    "\n",
    "print(f\"Processing {csv_path}...\")\n",
    "try:\n",
    "    samples = load_and_process_data(csv_path, images_folder_paths)\n",
    "    if not samples:\n",
    "        print(f\"No valid samples found in {csv_path}\")\n",
    "\n",
    "    train_samples, val_test_samples = train_test_split(samples, test_size=0.4, random_state=42)\n",
    "    val_samples, test_samples = train_test_split(val_test_samples, test_size=0.5, random_state=42)\n",
    "\n",
    "    ransac_model, inlier_mask, outlier_mask = train_ransac(train_samples)\n",
    "\n",
    "    train_mae, train_mse, _, _ = evaluate_samples(train_samples, ransac_model)\n",
    "    print(f\"Train Mean Absolute Error: {train_mae}\")\n",
    "    print(f\"Train Mean Squared Error: {train_mse}\")\n",
    "\n",
    "    val_mae, val_mse, _, _ = evaluate_samples(val_samples, ransac_model)\n",
    "    print(f\"Validation Mean Absolute Error: {val_mae}\")\n",
    "    print(f\"Validation Mean Squared Error: {val_mse}\")\n",
    "\n",
    "    test_mae, test_mse, y_test, y_test_pred = evaluate_samples(test_samples, ransac_model)\n",
    "    print(f\"Test Mean Absolute Error: {test_mae}\")\n",
    "    print(f\"Test Mean Squared Error: {test_mse}\")\n",
    "\n",
    "    plot_results(train_samples, val_samples, test_samples, ransac_model, inlier_mask)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error processing {csv_path}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541786f2-cc88-4d56-a6a6-40c8d97a2c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DA+RANSAC\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import pipeline\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import RANSACRegressor\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "depth_estimator = pipeline(task=\"depth-estimation\", model=\"depth-anything/Depth-Anything-V2-Small-hf\")\n",
    "\n",
    "def load_and_process_data(csv_path, images_folder_paths):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    samples = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        image_name = row['image_name']\n",
    "        image_path = find_image(images_folder_paths, image_name)\n",
    "        if not image_path:\n",
    "            continue\n",
    "        \n",
    "        image = Image.open(image_path)\n",
    "        x_coord, y_coord = int(row['x']), int(row['y'])\n",
    "        if not (0 <= x_coord < image.width and 0 <= y_coord < image.height):\n",
    "            continue\n",
    "        \n",
    "        true_depth = row['radius']\n",
    "        depth = depth_estimator(image)['depth']\n",
    "        depth_array = np.array(depth)  \n",
    "        predicted_depth = depth_array[y_coord, x_coord]\n",
    "        \n",
    "        \n",
    "        if predicted_depth < 0 or true_depth < 0:\n",
    "            continue\n",
    "        \n",
    "        samples.append((predicted_depth, true_depth, row['location']))\n",
    "\n",
    "    return samples\n",
    "\n",
    "def find_image(folder_paths, image_name):\n",
    "    for folder_path in folder_paths:\n",
    "        for root, _, files in os.walk(folder_path):\n",
    "            if image_name in files:\n",
    "                return os.path.join(root, image_name)\n",
    "    return None\n",
    "\n",
    "def train_ransac(samples):\n",
    "    X = np.array([s[0] for s in samples]).reshape(-1, 1)\n",
    "    y = np.array([s[1] for s in samples])\n",
    "    \n",
    "    ransac = RANSACRegressor(max_trials=300, min_samples=0.6, residual_threshold=1.5, random_state=42)\n",
    "    ransac.fit(X, y)\n",
    "    \n",
    "    inlier_mask = ransac.inlier_mask_\n",
    "    outlier_mask = np.logical_not(inlier_mask)\n",
    "    \n",
    "    return ransac, inlier_mask, outlier_mask\n",
    "\n",
    "def evaluate_samples(samples, model):\n",
    "    X = np.array([s[0] for s in samples]).reshape(-1, 1)\n",
    "    y_true = np.array([s[1] for s in samples])\n",
    "    y_pred = model.predict(X)\n",
    "    \n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    \n",
    "    return mae, mse, y_true, y_pred\n",
    "\n",
    "def plot_results(train_samples, val_samples, test_samples, model, inlier_mask):\n",
    "    def plot_fit_line(ax, X, y, y_pred, title, x_label, y_label):\n",
    "        ax.scatter(y, y_pred, alpha=0.5, label='Predicted vs True')\n",
    "        ax.set_xlabel(x_label)\n",
    "        ax.set_ylabel(y_label)\n",
    "        ax.set_title(title)\n",
    "        ax.legend()\n",
    "        ax.grid(True)\n",
    "        min_val = min(y.min(), y_pred.min())\n",
    "        max_val = max(y.max(), y_pred.max())\n",
    "        ax.plot([min_val, max_val], [min_val, max_val], color='red', linewidth=2, label='x=y')\n",
    "        fit_line = np.poly1d(np.polyfit(y, y_pred, 1))\n",
    "        fit_y = fit_line(y)\n",
    "        ax.plot(y, fit_y, color='blue', linewidth=2, label='Fit Line')\n",
    "        ax.legend()\n",
    "\n",
    "\n",
    "        fit_slope = fit_line.c[0]\n",
    "        angle = np.arctan(fit_slope) - np.pi / 4\n",
    "        angle_deg = np.degrees(angle)\n",
    "        print(f\"Angle between x=y and fit line in {title}: {angle_deg:.2f} degrees\")\n",
    "\n",
    "    plt.figure(figsize=(18, 5))\n",
    "    \n",
    "    X_train = np.array([s[0] for s in train_samples]).reshape(-1, 1)\n",
    "    y_train = np.array([s[1] for s in train_samples])\n",
    "    X_val = np.array([s[0] for s in val_samples]).reshape(-1, 1)\n",
    "    y_val = np.array([s[1] for s in val_samples])\n",
    "    X_test = np.array([s[0] for s in test_samples]).reshape(-1, 1)\n",
    "    y_test = np.array([s[1] for s in test_samples])\n",
    "    \n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_val_pred = model.predict(X_val)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    \n",
    "    plt.subplot(1, 3, 1)\n",
    "    plot_fit_line(plt.gca(), X_train, y_train, y_train_pred, 'Training Set', 'True Depth', 'Predicted Depth')\n",
    "    \n",
    "    plt.subplot(1, 3, 2)\n",
    "    plot_fit_line(plt.gca(), X_val, y_val, y_val_pred, 'Validation Set', 'True Depth', 'Predicted Depth')\n",
    "    \n",
    "    plt.subplot(1, 3, 3)\n",
    "    plot_fit_line(plt.gca(), X_test, y_test, y_test_pred, 'Test Set', 'True Depth', 'Predicted Depth')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    " \n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.scatter(y_train, y_train_pred, alpha=0.5, label='Train Set')\n",
    "    plt.xlabel('True Depth')\n",
    "    plt.ylabel('Predicted Depth')\n",
    "    plt.title('Training Set Fit Line')\n",
    "    plt.plot([min(y_train), max(y_train)], [min(y_train), max(y_train)], color='red', linewidth=2, label='x=y')\n",
    "    fit_line = np.poly1d(np.polyfit(y_train, y_train_pred, 1))\n",
    "    fit_y = fit_line(y_train)\n",
    "    plt.plot(y_train, fit_y, color='blue', linewidth=2, label='Fit Line')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "  \n",
    "    fit_slope = fit_line.c[0]\n",
    "    angle = np.arctan(fit_slope) - np.pi / 4\n",
    "    angle_deg = np.degrees(angle)\n",
    "    print(f\"Angle between x=y and fit line in Training Set: {angle_deg:.2f} degrees\")\n",
    "\n",
    "\n",
    "    print(f\"RANSAC model coefficients: {model.estimator_.coef_}\")\n",
    "    print(f\"RANSAC model intercept: {model.estimator_.intercept_}\")\n",
    "\n",
    "\n",
    "csv_path = r\"C:\\Users\\D-Frank\\Desktop\\111.csv\"\n",
    "images_folder_paths = [\n",
    "    r\"C:\\Users\\D-Frank\\Desktop\\data\\104RECNX\",\n",
    "    r\"C:\\Users\\D-Frank\\Desktop\\data\\105RECNX\",\n",
    "    r\"C:\\Users\\D-Frank\\Desktop\\data\\106RECNX\",\n",
    "    r\"C:\\Users\\D-Frank\\Desktop\\data\\107RECNX\",\n",
    "    r\"C:\\Users\\D-Frank\\Desktop\\data\\108RECNX\",\n",
    "    r\"C:\\Users\\D-Frank\\Desktop\\data\\110RECNX\",\n",
    "    r\"C:\\Users\\D-Frank\\Desktop\\data\\100RECNX\",\n",
    "    r\"C:\\Users\\D-Frank\\Desktop\\data\\101RECNX\",\n",
    "    r\"C:\\Users\\D-Frank\\Desktop\\data\\102RECNX\",\n",
    "    r\"C:\\Users\\D-Frank\\Desktop\\data\\103RECNX\"\n",
    "]\n",
    "\n",
    "print(f\"Processing {csv_path}...\")\n",
    "try:\n",
    "    samples = load_and_process_data(csv_path, images_folder_paths)\n",
    "    if not samples:\n",
    "        print(f\"No valid samples found in {csv_path}\")\n",
    "\n",
    "    train_samples, val_test_samples = train_test_split(samples, test_size=0.4, random_state=42)\n",
    "    val_samples, test_samples = train_test_split(val_test_samples, test_size=0.5, random_state=42)\n",
    "\n",
    "    ransac_model, inlier_mask, outlier_mask = train_ransac(train_samples)\n",
    "\n",
    "    train_mae, train_mse, _, _ = evaluate_samples(train_samples, ransac_model)\n",
    "    print(f\"Train Mean Absolute Error: {train_mae}\")\n",
    "    print(f\"Train Mean Squared Error: {train_mse}\")\n",
    "\n",
    "    val_mae, val_mse, _, _ = evaluate_samples(val_samples, ransac_model)\n",
    "    print(f\"Validation Mean Absolute Error: {val_mae}\")\n",
    "    print(f\"Validation Mean Squared Error: {val_mse}\")\n",
    "\n",
    "    test_mae, test_mse, y_test, y_test_pred = evaluate_samples(test_samples, ransac_model)\n",
    "    print(f\"Test Mean Absolute Error: {test_mae}\")\n",
    "    print(f\"Test Mean Squared Error: {test_mse}\")\n",
    "\n",
    "    plot_results(train_samples, val_samples, test_samples, ransac_model, inlier_mask)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error processing {csv_path}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11857a6a-1f17-4573-b8fd-7f09421ec46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DPT+PVCNN\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from transformers import DPTForDepthEstimation, DPTFeatureExtractor\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# PVCNN\n",
    "class PVCNN(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(PVCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels, 64, kernel_size=1)\n",
    "        self.conv2 = nn.Conv1d(64, 128, kernel_size=1)\n",
    "        self.conv3 = nn.Conv1d(128, 256, kernel_size=1)\n",
    "        self.fc1 = nn.Linear(256, 128)\n",
    "        self.fc2 = nn.Linear(128, out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = nn.ReLU()(x)\n",
    "        x = self.conv2(x)\n",
    "        x = nn.ReLU()(x)\n",
    "        x = self.conv3(x)\n",
    "        x = nn.ReLU()(x)\n",
    "        x = x.max(dim=2)[0]  \n",
    "        x = self.fc1(x)\n",
    "        x = nn.ReLU()(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model_name = \"Intel/dpt-large\"\n",
    "dpt_model = DPTForDepthEstimation.from_pretrained(model_name)\n",
    "feature_extractor = DPTFeatureExtractor.from_pretrained(model_name)\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "dpt_model.to(device)\n",
    "\n",
    "def load_and_process_data(csv_path, images_folder_paths):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    samples = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        image_name = row['image_name']\n",
    "        image_path = find_image(images_folder_paths, image_name)\n",
    "        if not image_path:\n",
    "            continue\n",
    "        \n",
    "        image = Image.open(image_path)\n",
    "        x_coord, y_coord = int(row['x']), int(row['y'])\n",
    "        if not (0 <= x_coord < image.width and 0 <= y_coord < image.height):\n",
    "            continue\n",
    "        \n",
    "        true_depth = row['radius']\n",
    "        inputs = feature_extractor(images=image, return_tensors=\"pt\").to(device)\n",
    "        with torch.no_grad():\n",
    "            outputs = dpt_model(**inputs)\n",
    "            predicted_depth = outputs.predicted_depth.squeeze()\n",
    "        \n",
    "        predicted_depth_array = torch.nn.functional.interpolate(\n",
    "            predicted_depth.unsqueeze(0).unsqueeze(0),\n",
    "            size=image.size[::-1],\n",
    "            mode=\"bicubic\",\n",
    "            align_corners=False,\n",
    "        ).squeeze().cpu().numpy()\n",
    "        \n",
    "        predicted_depth = predicted_depth_array[y_coord, x_coord]\n",
    "        samples.append((predicted_depth, true_depth, row['location']))\n",
    "\n",
    "    return samples\n",
    "\n",
    "def find_image(folder_paths, image_name):\n",
    "    for folder_path in folder_paths:\n",
    "        for root, _, files in os.walk(folder_path):\n",
    "            if image_name in files:\n",
    "                return os.path.join(root, image_name)\n",
    "    return None\n",
    "\n",
    "def train_pvcnn(train_samples, val_samples, learning_rate=0.001, epochs=100):\n",
    "    pvcnn = PVCNN(1, 1).to(device)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(pvcnn.parameters(), lr=learning_rate)\n",
    "\n",
    "    train_pred = torch.tensor([s[0] for s in train_samples], dtype=torch.float32).view(-1, 1, 1).to(device)\n",
    "    train_true = torch.tensor([s[1] for s in train_samples], dtype=torch.float32).view(-1, 1).to(device)\n",
    "    \n",
    "    val_pred = torch.tensor([s[0] for s in val_samples], dtype=torch.float32).view(-1, 1, 1).to(device)\n",
    "    val_true = torch.tensor([s[1] for s in val_samples], dtype=torch.float32).view(-1, 1).to(device)\n",
    "\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        pvcnn.train()\n",
    "        optimizer.zero_grad()\n",
    "        outputs = pvcnn(train_pred)\n",
    "        loss = criterion(outputs, train_true)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        pvcnn.eval()\n",
    "        with torch.no_grad():\n",
    "            val_outputs = pvcnn(val_pred)\n",
    "            val_loss = criterion(val_outputs, val_true)\n",
    "        \n",
    "        train_losses.append(loss.item())\n",
    "        val_losses.append(val_loss.item())\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Training Loss: {loss.item()}, Validation Loss: {val_loss.item()}\")\n",
    "\n",
    "    return pvcnn, train_losses, val_losses\n",
    "\n",
    "def evaluate_samples(samples, model):\n",
    "    model.eval()\n",
    "    depths_pred = torch.tensor([s[0] for s in samples], dtype=torch.float32).view(-1, 1, 1).to(device)\n",
    "    depths_true = np.array([s[1] for s in samples])\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        pred_abs = model(depths_pred).cpu().numpy().flatten()\n",
    "\n",
    "    mae = mean_absolute_error(depths_true, pred_abs)\n",
    "    mse = mean_squared_error(depths_true, pred_abs)\n",
    "    \n",
    "    return mae, mse\n",
    "\n",
    "def plot_losses(train_losses, val_losses):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(train_losses, label='Training Loss')\n",
    "    plt.plot(val_losses, label='Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "def plot_fit(samples, model, title):\n",
    "    model.eval()\n",
    "    depths_pred = torch.tensor([s[0] for s in samples], dtype=torch.float32).view(-1, 1, 1).to(device)\n",
    "    depths_true = np.array([s[1] for s in samples])\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        pred_abs = model(depths_pred).cpu().numpy().flatten()\n",
    "    \n",
    " \n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.scatter(depths_true, pred_abs, alpha=0.5, label='Predicted vs True')\n",
    "    \n",
    "\n",
    "    reg = LinearRegression().fit(depths_true.reshape(-1, 1), pred_abs)\n",
    "    pred_line = reg.predict(np.linspace(depths_true.min(), depths_true.max(), 100).reshape(-1, 1))\n",
    "    plt.plot(np.linspace(depths_true.min(), depths_true.max(), 100), pred_line, color='red', linewidth=2, label='Fit Line')\n",
    "\n",
    "  \n",
    "    plt.plot([depths_true.min(), depths_true.max()], [depths_true.min(), depths_true.max()], color='blue', linewidth=2, label='x=y')\n",
    "    \n",
    "  \n",
    "    fit_slope = reg.coef_[0]\n",
    "    angle = np.arctan(fit_slope) - np.pi / 4\n",
    "    angle_deg = np.degrees(angle)\n",
    "    print(f\"Angle between x=y and fit line in {title}: {angle_deg:.2f} degrees\")\n",
    "\n",
    "    plt.xlabel('True Depth')\n",
    "    plt.ylabel('Predicted Depth')\n",
    "    plt.title(f'Predicted vs True Depth ({title})')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "csv_path = r\"C:\\Users\\D-Frank\\Desktop\\111.csv\"\n",
    "images_folder_paths = [\n",
    "    r\"C:\\Users\\D-Frank\\Desktop\\data\\104RECNX\",\n",
    "    r\"C:\\Users\\D-Frank\\Desktop\\data\\105RECNX\",\n",
    "    r\"C:\\Users\\D-Frank\\Desktop\\data\\106RECNX\",\n",
    "    r\"C:\\Users\\D-Frank\\Desktop\\data\\107RECNX\",\n",
    "    r\"C:\\Users\\D-Frank\\Desktop\\data\\108RECNX\",\n",
    "    r\"C:\\Users\\D-Frank\\Desktop\\data\\110RECNX\",\n",
    "    r\"C:\\Users\\D-Frank\\Desktop\\data\\100RECNX\",\n",
    "    r\"C:\\Users\\D-Frank\\Desktop\\data\\101RECNX\",\n",
    "    r\"C:\\Users\\D-Frank\\Desktop\\data\\102RECNX\",\n",
    "    r\"C:\\Users\\D-Frank\\Desktop\\data\\103RECNX\"\n",
    "]\n",
    "\n",
    "print(f\"Processing {csv_path}...\")\n",
    "try:\n",
    "    samples = load_and_process_data(csv_path, images_folder_paths)\n",
    "    if not samples:\n",
    "        print(f\"No valid samples found in {csv_path}\")\n",
    "\n",
    "    locations = list(set([s[2] for s in samples]))\n",
    "    train_locations = locations[:6]\n",
    "    val_test_locations = locations[6:]\n",
    "\n",
    "    train_samples = [s for s in samples if s[2] in train_locations]\n",
    "    val_test_samples = [s for s in samples if s[2] in val_test_locations]\n",
    "\n",
    "    val_samples, test_samples = train_test_split(val_test_samples, test_size=0.5, random_state=42)\n",
    "\n",
    "    pvcnn_model, train_losses, val_losses = train_pvcnn(train_samples, val_samples)\n",
    "    torch.save(pvcnn_model.state_dict(), 'pvcnn1.pt')\n",
    "\n",
    "    train_mae, train_mse = evaluate_samples(train_samples, pvcnn_model)\n",
    "    print(f\"Train Mean Absolute Error: {train_mae}\")\n",
    "    print(f\"Train Mean Squared Error: {train_mse}\")\n",
    "\n",
    "    val_mae, val_mse = evaluate_samples(val_samples, pvcnn_model)\n",
    "    print(f\"Validation Mean Absolute Error: {val_mae}\")\n",
    "    print(f\"Validation Mean Squared Error: {val_mse}\")\n",
    "\n",
    "    test_mae, test_mse = evaluate_samples(test_samples, pvcnn_model)\n",
    "    print(f\"Test Mean Absolute Error: {test_mae}\")\n",
    "    print(f\"Test Mean Squared Error: {test_mse}\")\n",
    "\n",
    "    plot_losses(train_losses, val_losses)\n",
    "    plot_fit(train_samples, pvcnn_model, 'Training Set')\n",
    "    plot_fit(val_samples, pvcnn_model, 'Validation Set')\n",
    "    plot_fit(test_samples, pvcnn_model, 'Test Set')\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error processing {csv_path}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1da422-3b22-4d13-b4a4-d71f5df106ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DA+PVCNN\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from transformers import pipeline\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# PVCNN\n",
    "class PVCNN(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(PVCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels, 128, kernel_size=1)\n",
    "        self.conv2 = nn.Conv1d(128, 256, kernel_size=1)\n",
    "        self.conv3 = nn.Conv1d(256, 512, kernel_size=1)\n",
    "        self.fc1 = nn.Linear(512, 256)\n",
    "        self.fc2 = nn.Linear(256, out_channels)\n",
    "        self.dropout = nn.Dropout(0.5)  \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = nn.ReLU()(x)\n",
    "        x = self.conv2(x)\n",
    "        x = nn.ReLU()(x)\n",
    "        x = self.conv3(x)\n",
    "        x = nn.ReLU()(x)\n",
    "        x = x.max(dim=2)[0]  \n",
    "        x = self.fc1(x)\n",
    "        x = nn.ReLU()(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        x = nn.ReLU()(x) \n",
    "        return x\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "depth_estimator = pipeline(task=\"depth-estimation\", model=\"depth-anything/Depth-Anything-V2-Small-hf\")\n",
    "\n",
    "def load_and_process_data(csv_path, images_folder_paths):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    samples = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        image_name = row['image_name']\n",
    "        image_path = find_image(images_folder_paths, image_name)\n",
    "        if not image_path:\n",
    "            continue\n",
    "        \n",
    "        image = Image.open(image_path)\n",
    "        x_coord, y_coord = int(row['x']), int(row['y'])\n",
    "        if not (0 <= x_coord < image.width and 0 <= y_coord < image.height):\n",
    "            continue\n",
    "        \n",
    "        true_depth = row['radius']\n",
    "        depth = depth_estimator(image)['depth']\n",
    "        depth_array = np.array(depth)  \n",
    "        predicted_depth = depth_array[y_coord, x_coord]\n",
    "        \n",
    "     \n",
    "        if predicted_depth < 0 or true_depth < 0:\n",
    "            continue\n",
    "        \n",
    "        samples.append((predicted_depth, true_depth, row['location']))\n",
    "\n",
    "    return samples\n",
    "\n",
    "def find_image(folder_paths, image_name):\n",
    "    for folder_path in folder_paths:\n",
    "        for root, _, files in os.walk(folder_path):\n",
    "            if image_name in files:\n",
    "                return os.path.join(root, image_name)\n",
    "    return None\n",
    "\n",
    "def train_pvcnn(train_samples, val_samples, learning_rate=0.0001, epochs=300, batch_size=32):\n",
    "    pvcnn = PVCNN(1, 1).to(device)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(pvcnn.parameters(), lr=learning_rate)\n",
    "\n",
    "    train_pred = torch.tensor([s[0] for s in train_samples], dtype=torch.float32).view(-1, 1, 1).to(device)\n",
    "    train_true = torch.tensor([s[1] for s in train_samples], dtype=torch.float32).view(-1, 1).to(device)\n",
    "    \n",
    "    val_pred = torch.tensor([s[0] for s in val_samples], dtype=torch.float32).view(-1, 1, 1).to(device)\n",
    "    val_true = torch.tensor([s[1] for s in val_samples], dtype=torch.float32).view(-1, 1).to(device)\n",
    "\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        pvcnn.train()\n",
    "        permutation = torch.randperm(train_pred.size()[0])\n",
    "        for i in range(0, train_pred.size()[0], batch_size):\n",
    "            indices = permutation[i:i + batch_size]\n",
    "            batch_pred, batch_true = train_pred[indices], train_true[indices]\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = pvcnn(batch_pred)\n",
    "            loss = criterion(outputs, batch_true)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        pvcnn.eval()\n",
    "        with torch.no_grad():\n",
    "            val_outputs = pvcnn(val_pred)\n",
    "            val_loss = criterion(val_outputs, val_true)\n",
    "        \n",
    "        train_losses.append(loss.item())\n",
    "        val_losses.append(val_loss.item())\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Training Loss: {loss.item()}, Validation Loss: {val_loss.item()}\")\n",
    "\n",
    "    return pvcnn, train_losses, val_losses\n",
    "\n",
    "def evaluate_samples(samples, model):\n",
    "    model.eval()\n",
    "    depths_pred = torch.tensor([s[0] for s in samples], dtype=torch.float32).view(-1, 1, 1).to(device)\n",
    "    depths_true = np.array([s[1] for s in samples])\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        pred_abs = model(depths_pred).cpu().numpy().flatten()\n",
    "\n",
    "    mae = mean_absolute_error(depths_true, pred_abs)\n",
    "    mse = mean_squared_error(depths_true, pred_abs)\n",
    "    \n",
    "    return mae, mse\n",
    "\n",
    "def plot_losses(train_losses, val_losses):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(train_losses, label='Training Loss')\n",
    "    plt.plot(val_losses, label='Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "def plot_fit(samples, model, title):\n",
    "    model.eval()\n",
    "    depths_pred = torch.tensor([s[0] for s in samples], dtype=torch.float32).view(-1, 1, 1).to(device)\n",
    "    depths_true = np.array([s[1] for s in samples])\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        pred_abs = model(depths_pred).cpu().numpy().flatten()\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.scatter(depths_true, pred_abs, alpha=0.5, label='Predicted vs True')\n",
    "    \n",
    "    \n",
    "    reg = LinearRegression().fit(depths_true.reshape(-1, 1), pred_abs)\n",
    "    pred_line = reg.predict(np.linspace(depths_true.min(), depths_true.max(), 100).reshape(-1, 1))\n",
    "    plt.plot(np.linspace(depths_true.min(), depths_true.max(), 100), pred_line, color='red', linewidth=2, label='Fit Line')\n",
    "\n",
    " \n",
    "    plt.plot([depths_true.min(), depths_true.max()], [depths_true.min(), depths_true.max()], color='blue', linewidth=2, label='x=y')\n",
    "    \n",
    "    \n",
    "    fit_slope = reg.coef_[0]\n",
    "    angle = np.arctan(fit_slope) - np.pi / 4\n",
    "    angle_deg = np.degrees(angle)\n",
    "    print(f\"Angle between x=y and fit line in {title}: {angle_deg:.2f} degrees\")\n",
    "\n",
    "    plt.xlabel('True Depth')\n",
    "    plt.ylabel('Predicted Depth')\n",
    "    plt.title(f'Predicted vs True Depth ({title})')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "csv_path = r\"C:\\Users\\D-Frank\\Desktop\\111.csv\"\n",
    "images_folder_paths = [\n",
    "    r\"C:\\Users\\D-Frank\\Desktop\\data\\104RECNX\",\n",
    "    r\"C:\\Users\\D-Frank\\Desktop\\data\\105RECNX\",\n",
    "    r\"C:\\Users\\D-Frank\\Desktop\\data\\106RECNX\",\n",
    "    r\"C:\\Users\\D-Frank\\Desktop\\data\\107RECNX\",\n",
    "    r\"C:\\Users\\D-Frank\\Desktop\\data\\108RECNX\",\n",
    "    r\"C:\\Users\\D-Frank\\Desktop\\data\\110RECNX\",\n",
    "    r\"C:\\Users\\D-Frank\\Desktop\\data\\100RECNX\",\n",
    "    r\"C:\\Users\\D-Frank\\Desktop\\data\\101RECNX\",\n",
    "    r\"C:\\Users\\D-Frank\\Desktop\\data\\102RECNX\",\n",
    "    r\"C:\\Users\\D-Frank\\Desktop\\data\\103RECNX\"\n",
    "]\n",
    "\n",
    "print(f\"Processing {csv_path}...\")\n",
    "try:\n",
    "    samples = load_and_process_data(csv_path, images_folder_paths)\n",
    "    if not samples:\n",
    "        print(f\"No valid samples found in {csv_path}\")\n",
    "\n",
    "    locations = list(set([s[2] for s in samples]))\n",
    "    train_locations = locations[:6]\n",
    "    val_test_locations = locations[6:]\n",
    "\n",
    "    train_samples = [s for s in samples if s[2] in train_locations]\n",
    "    val_test_samples = [s for s in samples if s[2] in val_test_locations]\n",
    "\n",
    "    val_samples, test_samples = train_test_split(val_test_samples, test_size=0.5, random_state=42)\n",
    "\n",
    "    pvcnn_model, train_losses, val_losses = train_pvcnn(train_samples, val_samples)\n",
    "    \n",
    "    torch.save(pvcnn_model.state_dict(), 'pvcnn2.pt')\n",
    "    \n",
    "    train_mae, train_mse = evaluate_samples(train_samples, pvcnn_model)\n",
    "    print(f\"Train Mean Absolute Error: {train_mae}\")\n",
    "    print(f\"Train Mean Squared Error: {train_mse}\")\n",
    "\n",
    "    val_mae, val_mse = evaluate_samples(val_samples, pvcnn_model)\n",
    "    print(f\"Validation Mean Absolute Error: {val_mae}\")\n",
    "    print(f\"Validation Mean Squared Error: {val_mse}\")\n",
    "\n",
    "    test_mae, test_mse = evaluate_samples(test_samples, pvcnn_model)\n",
    "    print(f\"Test Mean Absolute Error: {test_mae}\")\n",
    "    print(f\"Test Mean Squared Error: {test_mse}\")\n",
    "\n",
    "    plot_losses(train_losses, val_losses)\n",
    "    plot_fit(train_samples, pvcnn_model, 'Training Set')\n",
    "    plot_fit(val_samples, pvcnn_model, 'Validation Set')\n",
    "    plot_fit(test_samples, pvcnn_model, 'Test Set')\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error processing {csv_path}: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
